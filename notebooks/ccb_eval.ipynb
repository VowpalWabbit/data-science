{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.ccb.dsjson.processor import Processor\n",
    "from Pipeline.ccb.dsjson.predictions import Predictor\n",
    "from Pipeline import azure_blob_logs\n",
    "from Pipeline.utils import Mapper\n",
    "from Pipeline.dataflow import MultilineFiles, PickleFiles, CsvFiles, Fileset\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_root = Path('/Users/alextaim/data/ccb')\n",
    "vw_cache_folder = Path('/Users/alextaim/data/.vw_cache')\n",
    "\n",
    "raw_folder = local_data_root.joinpath('raw')\n",
    "slim_folder = local_data_root.joinpath('slim')\n",
    "sample_folder = local_data_root.joinpath('sample')\n",
    "predict_folder = local_data_root.joinpath('predict.pickle')\n",
    "baseline_predict_folder = local_data_root.joinpath('baseline.predict')\n",
    "baseline_estimate_folder = local_data_root.joinpath('baseline.estimate')\n",
    "cfe_estimate_folder = local_data_root.joinpath('cfe.estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['/Users/alextaim/data/ccb/raw/01.json',\n",
    "    '/Users/alextaim/data/ccb/raw/02.json']\n",
    "\n",
    "raw = MultilineFiles(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VwPipeline import Loggers, Handlers\n",
    "from VwPipeline.VwCache import VwCache\n",
    "from VwPipeline.Vw import Vw\n",
    "from VwPipeline.VwOpts import dimension, product\n",
    "import pandas as pd\n",
    "\n",
    "#your vw path\n",
    "vw_path = r'vw'\n",
    "\n",
    "cache = VwCache(vw_cache_folder)\n",
    "vw = Vw(\n",
    "    vw_path,\n",
    "    cache,\n",
    "    handlers=[Handlers.WidgetHandler()],\n",
    "    )\n",
    "\n",
    "opts = pd.DataFrame(product(\n",
    "    dimension('#base', ['--ccb_explore_adf --dsjson   -P 1 --preserve_performance_counters --save_resume']),\n",
    "    dimension('#learning', ['--coin']),\n",
    "))\n",
    "preds = vw.train(files, opts, ['-p'])\n",
    "prediction_files = {preds.iloc[0]['!Job'].name: preds.iloc[0]['!Outputs']['-p']}\n",
    "prediction_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate slim dsjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.ccb.dsjson import processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.ccb.dsjson.processor import Processor\n",
    "\n",
    "processor = Processor()\n",
    "slim = MultilineFiles().init(raw.process(processor.process, path_gen=Mapper(raw_folder, slim_folder), process=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Pipeline.filters import UniformSampler\n",
    "from Pipeline.ccb.dsjson.processor import Processor\n",
    "\n",
    "sampler = UniformSampler(0.5)\n",
    "processor = Processor(filters=[lambda l: sampler.do(l)])\n",
    "sample = MultilineFiles().init(raw.process(processor.process, path_gen=Mapper(raw_folder, sample_folder), process=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.ccb.dsjson.predictions import Predictor\n",
    "\n",
    "predictor = Predictor(filters=[lambda l: True])\n",
    "baseline_preds = PickleFiles().init(raw.process(predictor.predict_df, path_gen=Mapper(raw_folder, baseline_predict_folder), process=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preestimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.estimators import Estimator, evaluate\n",
    "import Pipeline.ccb.estimators\n",
    "import json\n",
    "\n",
    "estimator = Estimator(factory = Pipeline.ccb.estimators.create, estimators = {'baseline1_old': ['ccb|ips_snips|0'], 'random': ['ccb|ips_snips|0']}, online_estimator = 'ccb|ips_snips|0', window='1min')\n",
    "baseline_preestimates = PickleFiles().init(baseline_preds.process(estimator.preestimate_df, path_gen=Mapper(baseline_predict_folder, baseline_estimate_folder), process=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = baseline_preestimates.open().resample('2min').sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][\"('online', 'ccb|ips_snips|0')\"].get(type='snips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['online'] = df.apply(lambda r: r[\"('online', 'ccb|ips_snips|0')\"].get('ips')['e'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['online'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluate predictions from vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.ccb.vw import predictions\n",
    "\n",
    "class VwPredicionsFiles(Fileset):\n",
    "    def _read(self, i, path):\n",
    "        print(f'{i}: {path}')\n",
    "        labels = self.label_fileset.read(i)\n",
    "        labels['_tmp'] = list(predictions.lines_2_slots(open(path)))\n",
    "        labels[('b', policy_name)] = labels.apply(lambda r: [ap[1][ap[0]] for ap in zip(r['a'], r['_tmp'])], axis = 1)\n",
    "        return labels[['t', 'a', 'r', 'p', 'n', ('b', policy_name)]]        \n",
    "\n",
    "    @staticmethod\n",
    "    def _write(path, o):\n",
    "        raise Exception('Not supported')\n",
    "\n",
    "    def __init__(self, files, label_fileset, policy_name):\n",
    "        super().__init__(files=files, reader=self._read, writer=VwPredicionsFiles._write)\n",
    "        self.label_fileset = label_fileset\n",
    "        self.policy_name = policy_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_name = '--coin'\n",
    "coin_predictions = prediction_files[policy_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(factory = Pipeline.ccb.estimators.create, estimators = {policy_name: ['ccb|ips_snips|0']}, window='1min')\n",
    "coin_preestimates = PickleFiles().init(VwPredicionsFiles(coin_predictions, baseline_preds, policy_name).process(estimator.preestimate_df, path_gen=Mapper(vw_cache_folder, cfe_estimate_folder), process=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_preestimates.open().resample('2min').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preestimates = pd.concat([estimator.read_preestimate(p) for p in preestimates])\n",
    "cfe_stats = evaluate(baseline_preestimates.resample('1min').sum())\n",
    "cfe_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_stats = baseline_stats.join(cfe_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38564bitfd59076926044bd899f4541e1d3f6749",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}