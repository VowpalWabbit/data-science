{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiailize VW executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vw_executor.vw import Vw\n",
    "\n",
    "vw = Vw('.vw_cache', 'vw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    'vw_executor/tests/data/cb_1000_0.json',\n",
    "    'vw_executor/tests/data/cb_1000_1.json', \n",
    "    ]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define options grid and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vw_executor.vw_opts import Grid\n",
    "\n",
    "opts = pd.DataFrame(Grid(\n",
    "    {\n",
    "        '#base': ['--ccb_explore_adf -P 10 --preserve_performance_counters --save_resume --dsjson --epsilon 0.2'],\n",
    "        '--cb_type': ['ips', 'mtr']\n",
    "    }) * (\n",
    "        Grid({'--learning_rate': range(1,5), '--power_t': [0]}) + Grid({'#coin': ['--coin']})\n",
    "    ))\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vw.train(inputs, opts, ['-p'])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the best one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpers (TDB: to write properly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def _logs_parse(lines):\n",
    "    for l in lines:\n",
    "        o = json.loads(l)\n",
    "        yield {'r': -o['_label_cost'], 'p': o['_label_probability'], 'a': o['_labelIndex']}\n",
    "        \n",
    "def _predictions_parse(lines):\n",
    "    for l in lines:\n",
    "        if ':' in l:\n",
    "            yield {int(kv.split(':')[0]): float(kv.split(':')[1]) for kv in l.split(',')}\n",
    "\n",
    "def logs_2_df(files):\n",
    "    return pd.DataFrame(_logs_parse(chain(*map(lambda f: open(f), files))))\n",
    "\n",
    "def predictions_2_df(files):\n",
    "    return pd.DataFrame(_predictions_parse(chain(*map(lambda f: open(f), files))))\n",
    "\n",
    "def _get_estimators_result(i, est, result):\n",
    "    from estimators.bandits import ips, clopper_pearson\n",
    "    result['i'].append(i)\n",
    "    result['online'].append(est['online'].get())\n",
    "    result['estimate'].append(est['estimate'].get())\n",
    "    int_result = est['interval'].get()\n",
    "    result['lower'].append(int_result[0])\n",
    "    result['upper'].append(int_result[1])\n",
    "\n",
    "def estimate_cb(decisions, window):\n",
    "    from estimators.bandits import ips, snips, clopper_pearson, gaussian\n",
    "    result = {'i': [], 'estimate': [], 'lower': [], 'upper': [], 'online': []}\n",
    "    est_default = lambda: {'estimate': ips.Estimator(), 'interval': gaussian.Interval(), 'online': ips.Estimator()}\n",
    "    est = est_default()\n",
    "    for i, row in decisions.iterrows():\n",
    "        p_log = row['p']\n",
    "        r = row['r']\n",
    "        p_pred = row[int(row['a'])]\n",
    "        est['estimate'].add_example(p_log, r, p_pred)\n",
    "        est['interval'].add_example(p_log, r, p_pred)\n",
    "        est['online'].add_example(p_log, r, p_log)\n",
    "        if ((i + 1) % window == 0):\n",
    "            _get_estimators_result(i, est, result)\n",
    "            est = est_default()\n",
    "\n",
    "    if est['online'].data['N'] > 2:\n",
    "        _get_estimators_result(i, est, result)\n",
    "       \n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def plot_cb(ax, estimates):\n",
    "    import matplotlib.pyplot as plt\n",
    "    y = estimates[f'estimate']\n",
    "    l = estimates[f'lower']\n",
    "    u = estimates[f'upper']\n",
    "    o = estimates[f'online']\n",
    "    ax.plot(estimates['i'], y, label='est')\n",
    "    ax.fill_between(estimates['i'], l, u, alpha=.1)\n",
    "    ax.plot(estimates['i'], o, label='online')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "def new_ax():\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig,ax = plt.subplots(dpi=100, figsize=[16,6])\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_job = result.sort_values(by='!Loss').iloc[0]['!Job']\n",
    "prediction_files = best_job.outputs['-p']\n",
    "decisions = pd.concat([logs_2_df(inputs), predictions_2_df(prediction_files)], axis=1)\n",
    "estimations = estimate_cb(decisions, 100)\n",
    "plot_cb(new_ax(), estimations)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6d91e144c1e8b75ccdd4259c6213e15c7f5d1d664ef01abea10605a34f365c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "050eed2c468e663e36bf60ef1d518c00a8957a7294b2c8543d052dd6fa68ab42"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
