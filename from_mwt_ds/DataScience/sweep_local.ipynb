{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "050eed2c468e663e36bf60ef1d518c00a8957a7294b2c8543d052dd6fa68ab42"
   }
  },
  "interpreter": {
   "hash": "e6d91e144c1e8b75ccdd4259c6213e15c7f5d1d664ef01abea10605a34f365c2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initiailize VW executor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from vw_executor.vw import Vw\r\n",
    "\r\n",
    "vw = Vw('vw','.vw_cache')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inputs = [\r\n",
    "    'vw_executor/tests/data/cb_1000_0.json',\r\n",
    "    'vw_executor/tests/data/cb_1000_1.json', \r\n",
    "    ]\r\n",
    "inputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define options grid and train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from vw_executor.vw_opts import dimension, product\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "opts = pd.DataFrame(product(\r\n",
    "    dimension('#base', ['--ccb_explore_adf -P 100 --preserve_performance_counters --save_resume --dsjson']),\r\n",
    "    dimension('--cb_type', ['ips', 'mtr']),\r\n",
    "    dimension('#interactions', ['', '-q ::'])\r\n",
    "))\r\n",
    "opts"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = vw.train(inputs, opts, ['-p'])\r\n",
    "result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the best one\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Some helpers (TDB: to write properly)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\r\n",
    "from itertools import chain\r\n",
    "\r\n",
    "\r\n",
    "def _logs_parse(lines):\r\n",
    "    for l in lines:\r\n",
    "        o = json.loads(l)\r\n",
    "        yield {'r': -o['_label_cost'], 'p': o['_label_probability'], 'a': o['_labelIndex']}\r\n",
    "        \r\n",
    "def _predictions_parse(lines):\r\n",
    "    for l in lines:\r\n",
    "        if ':' in l:\r\n",
    "            yield {int(kv.split(':')[0]): float(kv.split(':')[1]) for kv in l.split(',')}\r\n",
    "\r\n",
    "def logs_2_df(files):\r\n",
    "    return pd.DataFrame(_logs_parse(chain(*map(lambda f: open(f), files))))\r\n",
    "\r\n",
    "def predictions_2_df(files):\r\n",
    "    return pd.DataFrame(_predictions_parse(chain(*map(lambda f: open(f), files))))\r\n",
    "\r\n",
    "def _get_estimators_result(i, est, result):\r\n",
    "    from estimators.bandits import ips, clopper_pearson\r\n",
    "    result['i'].append(i)\r\n",
    "    result['online'].append(est['online'].get())\r\n",
    "    result['estimate'].append(est['estimate'].get())\r\n",
    "    int_result = est['interval'].get()\r\n",
    "    result['lower'].append(int_result[0])\r\n",
    "    result['upper'].append(int_result[1])\r\n",
    "\r\n",
    "def estimate_cb(decisions, window):\r\n",
    "    from estimators.bandits import ips, snips, clopper_pearson, gaussian\r\n",
    "    result = {'i': [], 'estimate': [], 'lower': [], 'upper': [], 'online': []}\r\n",
    "    est_default = lambda: {'estimate': ips.Estimator(), 'interval': gaussian.Interval(), 'online': ips.Estimator()}\r\n",
    "    est = est_default()\r\n",
    "    for i, row in decisions.iterrows():\r\n",
    "        p_log = row['p']\r\n",
    "        r = row['r']\r\n",
    "        p_pred = row[int(row['a'])]\r\n",
    "        est['estimate'].add_example(p_log, r, p_pred)\r\n",
    "        est['interval'].add_example(p_log, r, p_pred)\r\n",
    "        est['online'].add_example(p_log, r, p_log)\r\n",
    "        if ((i + 1) % window == 0):\r\n",
    "            _get_estimators_result(i, est, result)\r\n",
    "            est = est_default()\r\n",
    "\r\n",
    "    if est['online'].data['N'] > 2:\r\n",
    "        _get_estimators_result(i, est, result)\r\n",
    "       \r\n",
    "    return pd.DataFrame(result)\r\n",
    "\r\n",
    "def plot_cb(ax, estimates):\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "    y = estimates[f'estimate']\r\n",
    "    l = estimates[f'lower']\r\n",
    "    u = estimates[f'upper']\r\n",
    "    o = estimates[f'online']\r\n",
    "    ax.plot(estimates['i'], y, label='est')\r\n",
    "    ax.fill_between(estimates['i'], l, u, alpha=.1)\r\n",
    "    ax.plot(estimates['i'], o, label='online')\r\n",
    "    plt.legend(loc='best')\r\n",
    "\r\n",
    "def new_ax():\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "    fig,ax = plt.subplots(dpi=100, figsize=[16,6])\r\n",
    "    return ax"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_job = result.sort_values(by='!Loss').iloc[0]['!Job']\r\n",
    "prediction_files = best_job.outputs['-p']\r\n",
    "decisions = pd.concat([logs_2_df(inputs), predictions_2_df(prediction_files)], axis=1)\r\n",
    "estimations = estimate_cb(decisions, 100)\r\n",
    "plot_cb(new_ax(), estimations)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}