{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Workspace\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or Attach AML Compute\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"rlos-cfe-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use simple script\n",
    "# CP script-run\n",
    "# cb to script-run\n",
    "import shutil, os\n",
    "source_directory = 'script-run'\n",
    "shutil.rmtree(source_directory)\n",
    "os.makedirs(source_directory, exist_ok=True)\n",
    "shutil.copytree('cb', os.path.join(source_directory, 'cb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $source_directory/estimate.py\n",
    "\n",
    "# %%run $source_directory/hello.py\n",
    "\n",
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "import sys\n",
    "import os\n",
    "from mpi4py import MPI\n",
    "\n",
    "print(\"*********************************************************\")\n",
    "print(\"Hello Azure ML!\")\n",
    "\n",
    "mounted_input_path = sys.argv[1]\n",
    "mounted_output_path = sys.argv[2]\n",
    "\n",
    "print(\"Argument 1: %s\" % mounted_input_path)\n",
    "print(\"Argument 2: %s\" % mounted_output_path)\n",
    "print(\"Number of nodes {}:\".format(MPI.COMM_WORLD.Get_size()))\n",
    "print(\"Node index {}:\".format(MPI.COMM_WORLD.Get_rank()))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if MPI.COMM_WORLD.Get_rank() == 0:\n",
    "    df = pd.read_csv(os.path.join(mounted_input_path, '01.csv'), parse_dates=['t']).set_index('t')\n",
    "elif MPI.COMM_WORLD.Get_rank() == 1:\n",
    "    df = pd.read_csv(os.path.join(mounted_input_path, '02.csv'), parse_dates=['t']).set_index('t')\n",
    "\n",
    "from cb.estimators import ips_snips\n",
    "\n",
    "\n",
    "def init_ips_snips(r, p, p_log, n):\n",
    "    result = ips_snips()\n",
    "    result.add(r, p_log, p, n * int(p > 0))\n",
    "    return result\n",
    "\n",
    "policies = ['random', 'baseline1']\n",
    "for p in policies:\n",
    "    df[p] = df.apply(lambda r: init_ips_snips(r['r'], r[f\"('b', '{p}')\"], r['p'], r['n']), axis = 1)\n",
    "\n",
    "df = df[policies].resample('5min').sum()\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_blob_store = ws.get_default_datastore()\n",
    "print(def_blob_store)\n",
    "import sys\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "print(sys.path)\n",
    "def_blob_store.upload_files(files = [\"test_data/cb/01.csv\", \"test_data/cb/02.csv\"],\n",
    "                        target_path = '/dataset/cb/',\n",
    "                       overwrite = True,\n",
    "                       show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "input_data = Dataset.File.from_files(def_blob_store.path('/dataset/cb/*')).as_named_input('input').as_mount()\n",
    "output = OutputFileDatasetConfig(destination=(def_blob_store, 'sample/outputdataset'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = Environment(\"myenv\")\n",
    "myenv.docker.enabled = True\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(pip_packages=['azureml-sdk>=1.12.0', 'pandas','matplotlib','mpi4py'])\n",
    "myenv.docker.base_image = 'mcr.microsoft.com/azureml/intelmpi2018.3-cuda9.0-cudnn7-ubuntu16.04'\n",
    "docker_config = DockerConfiguration(use_docker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "src = ScriptRunConfig(source_directory=source_directory, \n",
    "                      script='estimate.py', \n",
    "                      # to mount the dataset on the remote compute and pass the mounted path as an argument to the training script\n",
    "                      arguments =[input_data, output],\n",
    "                      compute_target=compute_target,\n",
    "                      environment=myenv,\n",
    "                      distributed_job_config=MpiConfiguration(node_count=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build and Submit Experiment\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(ws, 'ScriptRun_parallel')\n",
    "run = exp.submit(config=src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Run Details\n",
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
